#!/usr/bin/env python3

import rospy
import numpy as np
from geometry_msgs.msg import Pose
from std_msgs.msg import Float32
from sawyer_move.msg import YoyoState, RobotState
import cv2
import EasyPySpin
import apriltag
from PIL import Image
import time

class Tracking:
    def __init__(self):
        # self.pos_pub = rospy.Publisher('yoyo_pos', Float32, queue_size=10)
        # self.vel_pub = rospy.Publisher('yoyo_vel', Float32, queue_size=10)
        # self.rot_pub = rospy.Publisher('yoyo_rot', Float32, queue_size=10)
        self.yoyo_state_pub = rospy.Publisher('yoyo_state', YoyoState, queue_size=10)
        self.robot_state_pub = rospy.Subscriber('robot_state', RobotState, self.robot_state_callback)


        self.dis_per_pixel = 0.0
        self.mirr_dis_per_pixel = 0.0
        self.robot_origin_z = 0
        self.ee_z_pos = 0.0

        self.last_rot = 0.0

        #Initializing april tags
        print("[INFO] detecting AprilTags...")
        self.options = apriltag.DetectorOptions(families="tag25h9", nthreads=8, quad_decimate=1)
        self.detector = apriltag.Detector(self.options)

        #Initializing camera
        self.cap = EasyPySpin.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_GAIN, 0.0)
        self.cap.set(cv2.CAP_PROP_EXPOSURE, 1000.0)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 548)
        self.cap.set_pyspin_value("AdcBitDepth", "Bit8")
        self.cap.set(cv2.CAP_PROP_FPS, 500)
        
        





        fps  = self.cap.get_pyspin_value("AcquisitionFrameRate")
        print('fps ' + str(fps))
        width  = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)
        print("image width: " + str(width))
        height = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
        print("image height: " + str(height))


        self.last_yoyo_z_dis = 0.0
        self.last_yoyo_pos_time = time.time()

    def robot_state_callback(self, data):
        self.ee_z_pos = data.ee_z_pos

    #     self.load_coefficients()

        
    # def load_coefficients(self):
    #     '''Loads camera matrix and distortion coefficients.'''
    #     # FILE_STORAGE_READ
    #     cv_file = cv2.FileStorage('../Final Project Experiment/tracking_yoyo', cv2.FILE_STORAGE_READ)

    #     # note we also have to specify the type to retrieve other wise we only get a
    #     # FileNode object back instead of a matrix
    #     camera_matrix = cv_file.getNode('K').mat()
    #     dist_matrix = cv_file.getNode('D').mat()

    #     cv_file.release()
    #     return [camera_matrix, dist_matrix]

    def apriltag_detection(self, gray_img, id):
        results = self.detector.detect(gray_img)
        #print("[INFO] {} total AprilTags detected".format(len(results)))
        # loop over the AprilTag detection results


        yoyo_center = []
        yoyo_visible = False
        yoyo_rotation = self.last_rot
        for i in range(len(results)):
            r = results[i]
            # extract the bounding box (x, y)-coordinates for the AprilTag
            # and convert each of the (x, y)-coordinate pairs to integers
            (ptA, ptB, ptC, ptD) = r.corners
            ptB = (int(ptB[0]), int(ptB[1]))
            ptC = (int(ptC[0]), int(ptC[1]))
            ptD = (int(ptD[0]), int(ptD[1]))
            ptA = (int(ptA[0]), int(ptA[1]))
            # draw the bounding box of the AprilTag detection
            cv2.line(gray_img, ptA, ptB, (0, 255, 0), 2)
            cv2.line(gray_img, ptB, ptC, (0, 255, 0), 2)
            cv2.line(gray_img, ptC, ptD, (0, 255, 0), 2)
            cv2.line(gray_img, ptD, ptA, (0, 255, 0), 2)
            # draw the center (x, y)-coordinates of the AprilTag
            (cX, cY) = (int(r.center[0]), int(r.center[1]))

            cv2.circle(gray_img, (cX, cY), 5, (0, 0, 255), -1)
            # draw the tag family on the image
            tagID = str(r.tag_id)#tag_family.decode("utf-8")
            if r.tag_id == id:
                #yoyo_center.append((cX,cY))
                #print(cX,cY)
                yoyo_center = [cX, cY]

                if r.tag_id == 0:
                    yoyo_visible = True
                    pos_results, _, _ = self.detector.detection_pose(r, camera_params=np.array([729.78671005,731.29832261,362.9618687,268.38005998]), tag_size=0.053)
                    yoyo_rotation = np.arctan2(pos_results[1][0], pos_results[0][0])

            cv2.putText(gray_img, tagID, (ptA[0], ptA[1] - 15),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            #print("[INFO] tag family: {}".format(tagFamily))



        return yoyo_center, yoyo_visible, yoyo_rotation

    def get_tag(self, id, mirror=False):
        ret, frame = self.cap.read()
        if mirror:
            frame = np.array(np.fliplr(frame[50:500, 370:540]))

        tags_center = self.apriltag_detection(frame, id) #two tags are 0.2m away vertically

        return tags_center

    def get_pixel_distance(self, tag_1_center, tag_2_center):
        pixel_diff = tag_2_center[1] - tag_1_center[1] #tag2 - tag1
        dis_diff = 0.2 #meter
        return dis_diff/pixel_diff #meter
        

    def measure(self):
        
        ret, frame = self.cap.read()
        yoyo_center, yoyo_visible, yoyo_rotation = self.apriltag_detection(frame, 0)

        if yoyo_visible == False:
            mirror_yoyo_visible = False
            frame = np.array(np.fliplr(frame[50:500, 370:540]))
            mirror_yoyo_center, mirror_yoyo_visible, mirror_yoyo_rotation = self.apriltag_detection(frame, 0)
            yoyo_center = mirror_yoyo_center
            yoyo_rotation = mirror_yoyo_rotation

            # if mirror_yoyo_visible is False:
            #     rospy.logwarn("Cannot detect yoyo in the view and in the mirror")

        if len(yoyo_center) != 0:
            if yoyo_visible == False:
                yoyo_z_dis = (yoyo_center[1] * self.mirr_dis_per_pixel - 0.01) - (self.robot_origin_z*self.mirr_dis_per_pixel) + self.ee_z_pos
                
            else:
                yoyo_z_dis = (yoyo_center[1] * self.dis_per_pixel) - (self.robot_origin_z*self.dis_per_pixel) + self.ee_z_pos
            
            #print("distance from the top: " + str(yoyo_z_dis))

            # self.pos_pub.publish(Float32(yoyo_z_dis))
            # curr_time = time.time()
            # self.vel_pub.publish((yoyo_z_dis - self.last_yoyo_z_dis)/(curr_time - self.last_yoyo_pos_time))
            # self.rot_pub.publish(Float32(yoyo_rotation))

            curr_time = time.time()
            yoyo_z_vel = (yoyo_z_dis - self.last_yoyo_z_dis)/(curr_time - self.last_yoyo_pos_time)
            yoyo_rot_vel = (yoyo_rotation - self.last_rot)/(curr_time - self.last_yoyo_pos_time)

            yoyo_state = YoyoState()
            yoyo_state.yoyo_pos = yoyo_z_dis
            yoyo_state.yoyo_posvel = yoyo_z_vel
            yoyo_state.yoyo_rot = yoyo_rotation
            yoyo_state.yoyo_rotvel = yoyo_rot_vel

            self.yoyo_state_pub.publish(yoyo_state)


            self.last_rot = yoyo_rotation
            self.last_yoyo_z_dis = yoyo_z_dis
            self.last_yoyo_pos_time = curr_time

        # cv2.imshow('img', frame)
        # key = cv2.waitKey(1)
    

def main():
    rospy.init_node('tracking')
    r = rospy.Rate(500)

    tracking = Tracking()


    # #calibrate
    # tracking.dis_per_pixel = tracking.get_pixel_distance(tracking.get_tag(1)[0], tracking.get_tag(2)[0])
    # print(tracking.dis_per_pixel)

    # tracking.mirr_dis_per_pixel = tracking.get_pixel_distance(tracking.get_tag(1, True)[0], tracking.get_tag(2, True)[0])
    # print(tracking.mirr_dis_per_pixel)

    tracking.dis_per_pixel = 0.002127659574468085
    tracking.mirr_dis_per_pixel = 0.002702702702702703
    tracking.robot_origin_z = 188

    while not rospy.is_shutdown():

        tracking.measure()
        r.sleep()


if __name__ == '__main__':
    main()